{
  "input": {
    "agent1_file": "app/output\\agent1_combined_out_20260226_165406.json",
    "agent2_file": "app/output\\agent2_out_20260226_165406.json",
    "doc_type": "combined_resume_and_jd",
    "rounds": [
      "Round 2 - Technical Round"
    ]
  },
  "top_30": [
    {
      "round": "Round 2 - Technical Round",
      "question": "You developed Customer Churn Prediction models using TensorFlow. Can you describe the end-to-end process, from data ingestion to model deployment, and how you achieved a 15% reduction in false positives?",
      "answer": "Context: In my Machine Learning Intern role at Space-O Technology, I was tasked with developing customer churn prediction models. The primary goal was to accurately identify customers at risk of churning while minimizing false positives to optimize retention efforts.\nApproach: The process began with data ingestion from various sources, followed by extensive data cleaning and feature engineering. I used Pandas and NumPy for these steps, creating features like customer activity metrics, historical interactions, and demographic data. For model development, I leveraged TensorFlow to build a deep learning classification model. To reduce false positives, I focused on hyperparameter optimization using Grid Search, carefully tuning parameters such as learning rate, batch size, and network architecture (number of layers and neurons). I also experimented with different loss functions and class weighting to address potential class imbalance, which is common in churn datasets.\nExample: For the 15% reduction in false positives, after initial model training, I analyzed the confusion matrix. I found that a significant number of non-churning customers were being incorrectly flagged (false positives). By applying Grid Search, I systematically explored different combinations of hyperparameters. For instance, I found that a slightly higher L2 regularization on the weights and a specific learning rate schedule significantly improved the model's ability to distinguish between actual churners and non-churners, leading to the observed reduction. I also implemented a custom thresholding strategy on the model's output probabilities, adjusting it based on the business cost of false positives versus false negatives.\nPitfalls: A common pitfall is overfitting, especially with deep learning models on potentially imbalanced datasets. Another challenge was ensuring feature relevance and avoiding data leakage during feature engineering. Over-reliance on accuracy as a metric can also be misleading; precision, recall, and F1-score were crucial for evaluating churn prediction.\nHow you validate: Model performance was validated using a dedicated test set, ensuring it was representative of real-world data. I tracked metrics like precision, recall, F1-score, and AUC-ROC, with a specific focus on precision for reducing false positives. A/B testing or shadow deployment in a production-like environment would be the next step for real-world validation.",
      "focus_area": "Machine Learning Lifecycle",
      "difficulty": "hard"
    },
    {
      "round": "Round 2 - Technical Round",
      "question": "You refactored training workflows with vectorised NumPy operations, resulting in a 20% acceleration. Can you explain the concept of vectorization and provide a specific example from your experience?",
      "answer": "Context: During my Machine Learning Intern role at Space-O Technology, I identified a bottleneck in our model training workflows where iterative operations on large datasets were significantly slowing down the process. The goal was to optimize these operations for speed.\nApproach: Vectorization is the process of performing operations on entire arrays or matrices at once, rather than element by element using explicit loops. NumPy is highly optimized for vectorized operations because its underlying implementation is written in C, which allows for efficient memory access and parallel processing. By replacing Python loops with equivalent NumPy array operations, we can drastically reduce execution time.\nExample: A specific example involved feature scaling. Initially, our workflow iterated through each feature column and then each data point to apply min-max scaling. This looked something like:\n```python\nfor i in range(data.shape[1]): # Iterate columns\n    min_val = data[:, i].min()\n    max_val = data[:, i].max()\n    for j in range(data.shape[0]): # Iterate rows\n        data[j, i] = (data[j, i] - min_val) / (max_val - min_val)\n```\nI refactored this using NumPy's vectorized operations:\n```python\nmin_vals = data.min(axis=0) # Get min for each column\nmax_vals = data.max(axis=0) # Get max for each column\ndata_scaled = (data - min_vals) / (max_vals - min_vals)\n```\nThis vectorized approach eliminated the explicit Python loops, allowing NumPy to perform the operations much more efficiently, leading to the 20% acceleration in training speed for large datasets. The acceleration was particularly noticeable with datasets containing millions of rows and hundreds of features.\nPitfalls: While powerful, vectorization can sometimes lead to increased memory consumption if intermediate arrays are created unnecessarily. It also requires a good understanding of NumPy's broadcasting rules. Debugging vectorized code can sometimes be less intuitive than looped code.\nHow you validate: I validated the acceleration by profiling the code before and after refactoring using Python's `time` module or `cProfile`. I also ensured the numerical output of the scaled data remained identical to the original, non-vectorized approach to confirm correctness.",
      "focus_area": "Performance Optimization",
      "difficulty": "medium"
    },
    {
      "round": "Round 2 - Technical Round",
      "question": "You built a Medical Analysis Agent using Google Gemini and Flask. Describe the architecture of this agent and how you achieved 95% extraction accuracy on OCR for prescription images.",
      "answer": "Context: The Healthcare Helper project aimed to automate the extraction of clinical data from prescription images, which is a critical step in digitizing medical records. I chose Google Gemini for its multimodal capabilities and Flask for the web interface.\nApproach: The architecture involved a Flask backend serving as the API endpoint and orchestrator, a frontend (simple HTML/JS, or could be Streamlit/FastAPI for a more complex UI) for image upload, and Google Gemini as the core intelligence. When a user uploads a prescription image:\n1.  The Flask application receives the image.\n2.  It preprocesses the image (e.g., resizing, contrast enhancement) using OpenCV to optimize it for OCR.\n3.  The preprocessed image is then sent to the Google Gemini API. I used Gemini's multimodal capabilities, specifically its vision understanding, to interpret the image content.\n4.  I employed prompt engineering to guide Gemini. The prompt instructed Gemini to act as a medical data extractor, specifying the exact fields to extract (e.g., patient name, medication, dosage, frequency, doctor's signature) and their expected formats. I also included examples of prescription text and desired output formats (e.g., JSON).\n5.  Gemini processes the image and returns the extracted data, typically in a structured format like JSON, based on the prompt.\n6.  The Flask application then parses this response and returns it to the user.\nTo achieve 95% extraction accuracy, several factors were crucial:\n*   **Image Preprocessing:** Robust image preprocessing (e.g., binarization, noise reduction, deskewing) using OpenCV was essential to improve the clarity of text for Gemini's OCR capabilities.\n*   **Prompt Engineering:** Iterative refinement of the prompt was key. I provided clear instructions, few-shot examples of prescription images and their correct extractions, and specified constraints on the output format. I also included instructions for handling ambiguous or missing information.\n*   **Error Handling and Validation:** The Flask application included logic to validate the extracted data against expected patterns (e.g., regex for dosages). If Gemini's output was ambiguous or low-confidence, the system would flag it for manual review or attempt re-prompting with additional context.\nExample: For a prescription image, the prompt would be structured like: 'You are a medical data extraction agent. Extract patient name, medication, dosage, and frequency from the following prescription image. Output in JSON format: {'patient_name': '', 'medication': [{'name': '', 'dosage': '', 'frequency': ''}]}.' I then provided examples of how to handle different handwriting styles or layouts.\nPitfalls: Challenges included variations in prescription formats, handwriting legibility, and the inherent 'hallucination' risk with LLMs. Overcoming these required extensive prompt tuning and robust post-processing validation.\nHow you validate: Accuracy was measured by comparing the extracted data against manually annotated ground truth data for a diverse set of prescription images. I calculated the F1-score for each extracted field to ensure high precision and recall.",
      "focus_area": "Generative AI & Agentic Workflows",
      "difficulty": "hard"
    }
  ],
  "top_20_questions": [
    "You developed Customer Churn Prediction models using TensorFlow. Can you describe the end-to-end process, from data ingestion to model deployment, and how you achieved a 15% reduction in false positives?",
    "You refactored training workflows with vectorised NumPy operations, resulting in a 20% acceleration. Can you explain the concept of vectorization and provide a specific example from your experience?",
    "You built a Medical Analysis Agent using Google Gemini and Flask. Describe the architecture of this agent and how you achieved 95% extraction accuracy on OCR for prescription images.",
    "How do you approach designing automated data cleaning and normalisation pipelines, as you did at FusionBit? What are some common challenges and how do you address them?",
    "Your Spotify Preference Modelling project used K-Means clustering and PCA. Explain how PCA contributes to a recommendation engine and what considerations you made when choosing the number of components.",
    "The job description mentions 'Agentic workflows'. Based on your experience with multi-agent systems and the Healthcare Helper project, how would you define an agentic workflow in the context of business solutions, and what are its key components?",
    "Given your experience with Docker and CI/CD, how would you containerize and deploy a Flask-based AI application like your Medical Analysis Agent to a production environment, considering scalability and maintainability?",
    "Describe your experience with prompt engineering for LLMs. What are some best practices you follow to get reliable and accurate outputs from models like Google Gemini?",
    "How do you handle class imbalance in a dataset, particularly in a churn prediction scenario where churners are typically a minority class?",
    "You have experience with Python, but the role also mentions C# and .NET. How do you approach learning a new programming language and framework, and how quickly do you expect to become proficient?",
    "In your Face Recognition Attendance System, you used Python and OpenCV. What were the key challenges in achieving real-time performance and accuracy, and how did you overcome them?",
    "Discuss the trade-offs between different machine learning model architectures (e.g., deep learning vs. traditional ML) for a predictive analytics task like customer churn. When would you choose one over the other?",
    "How do you ensure the quality and reliability of data when designing data cleaning pipelines? What steps do you take to prevent data loss or unintended transformations?",
    "Imagine you need to integrate your Medical Analysis Agent into a larger Dynamics 365 Business Central application. What are the key considerations for API design, security, and data exchange?",
    "What is the importance of automated testing in a CI/CD pipeline for AI/ML applications? Can you give examples of different types of tests you would implement?",
    "Explain the concept of 'feature engineering' with an example from your Spotify Preference Modelling or Customer Churn Prediction projects. How do you decide which features to create?",
    "How do you monitor the performance of a deployed machine learning model in production? What metrics would you track, and what actions would you take if performance degrades?",
    "The job mentions 'scalable, high-performance AI/Model-first features'. How do you design an AI solution to be scalable from the ground up, considering data volume, model complexity, and user load?",
    "Describe a time you encountered a complex technical problem in one of your projects or internships. How did you approach debugging and resolving it?",
    "What are your thoughts on the ethical considerations and potential biases in AI models, especially in sensitive domains like healthcare or customer prediction? How would you mitigate them?"
  ],
  "notes": [
    "The candidate's resume indicates a 'Dec 2025 â€“ Present' start date for Recruit Riders Technologies, which is in the future relative to the JD's Feb 2026 post date. This was treated as current experience for question generation.",
    "Agent 2 JSON was empty, so company-specific context for Microsoft was derived solely from the job description.",
    "All questions are tailored to 'Round 2 - Technical Round' as specified by the user, covering ML, AI, software engineering, data, and MLOps topics relevant to both the candidate's experience and the job description.",
    "Model returned 3 items in top_30 (expected 30). Consider re-running with lower temperature."
  ]
}